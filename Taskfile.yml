version: "3"

# dotenv: ['secrets.env']
env:
  TF_VAR_cluster_name: liatrio-demo

silent: false
vars:
  KUBECTL: kubectl 
  GRUNT: terragrunt
  DOCKER_SOCK: /var/run/docker.sock

  RESET: \033[0m
  BLACK: \033[:0;30m
  RED: \033[:0;31m
  BLUE: \033[:0;34m
  YELLOW: \033[:0;33m
  GREEN: \033[:0;32m

# TODO: Create a subtaskfile and
# use overrides/inheritance?
tasks:
  all:
    desc: |
      Create a dev and prod cluster 
    cmds:
      - task: dev
      - task: prod
      - task: dev:dns:apply
      - task: prod:dns:apply

  destroy:
    desc: |
      Destroy a dev and prod cluster 
    cmds:
      - task: dev:cluster:destroy
      - task: prod:cluster:destroy

  dev:
    desc: |
        Create a local k3d cluster. 
        Requires a docker socket (linux only?)
    cmds:
      - task: dev:cluster:apply
      - task: dev:platform:apply
    preconditions:
      - test -S {{.DOCKER_SOCK}}

  prod:
    desc: |
      Create a digitalocean cluster. 
    cmds:
      - task: prod:cluster:apply
      - task: prod:platform:apply


  ##################
  ### Dev cluster
  ##################
  dev:cluster:plan:
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: dev
      MODULE: cluster
      OP: plan

  dev:cluster:apply:
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: dev
      MODULE: cluster
      OP: apply

  # Note! Dependency order is reversed
  dev:cluster:destroy:
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    deps: ["{{.ENVIRONMENT}}:platform:destroy"]
    cmds:
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: dev
      MODULE: cluster
      OP: destroy



  ################
  ## Dev platform
  dev:platform:plan:
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: dev
      MODULE: platform
      OP: plan

  dev:platform:apply:
    interactive: true
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: dev
      MODULE: platform
      OP: apply

  dev:dns:plan:
    desc: Mock a certificate issuer
    interactive: true
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: dev
      MODULE: dns
      OP: plan

  dev:dns:apply:
    desc: Point domain to ingress gateway loadbalancer
    interactive: true
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: dev
      MODULE: dns
      OP: apply



  # This times out
  # # Note! Dependency order is reversed
  # dev:platform:destroy:
  #   interactive: true
  #   desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
  #   dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
  #   cmds:
  #   - "{{.GRUNT}} {{.OP}}"
  #   vars:
  #     ENVIRONMENT: dev
  #     MODULE: platform
  #     OP: destroy


  dev:platform:destroy:
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    interactive: true
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    deps: ["{{.ENVIRONMENT}}:dns:destroy"]
    cmds:
    - cmd: "rm -fi terraform.tfstate terraform.tfstate.backup"
      ignore_error: true
    vars:
      ENVIRONMENT: dev
      MODULE: platform
      OP: destroy

  dev:dns:destroy:
    desc: Tear down domain
    interactive: true
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: dev
      MODULE: dns
      OP: destroy



  ##################
  ### Prod cluster
  ##################
  prod:cluster:plan:
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: prod
      MODULE: cluster
      OP: plan

  prod:cluster:apply:
    interactive: true
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: prod
      MODULE: cluster
      OP: apply

  prod:cluster:destroy:
    interactive: true
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: prod
      MODULE: cluster
      OP: destroy


  ################
  ## Prod platform
  prod:platform:plan:
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: prod
      MODULE: platform
      OP: plan

  prod:platform:apply:
    interactive: true
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: prod
      MODULE: platform
      OP: apply

  # # This destroy operation times-out
  # # We'll skip it.
  #
  # # Note! Dependency order is reversed
  # prod:platform:destroy:
  #   desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
  #   dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
  #   cmds:
  #   - "{{.GRUNT}} {{.OP}}"
  #   vars:
  #     ENVIRONMENT: prod
  #     MODULE: platform
  #     OP: destroy

  prod:platform:destroy:
    desc: terraform {{.OP}} the {{.ENVIRONMENT}} {{.MODULE}}
    interactive: true
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    deps: ["{{.ENVIRONMENT}}:cluster:destroy"]
    cmds:
    - cmd: "rm -fi terraform.tfstate terraform.tfstate.backup"
      ignore_error: true
    vars:
      ENVIRONMENT: prod
      MODULE: platform
      OP: destroy

  #################################
  ### DNS & Domains
  #################################
  prod:dns:plan:
    desc: Point domain to ingress gateway loadbalancer
    interactive: true
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: prod
      MODULE: dns
      OP: plan

  prod:dns:apply:
    desc: Point domain to ingress gateway loadbalancer
    interactive: true
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: prod
      MODULE: dns
      OP: apply

  prod:dns:destroy:
    desc: Tear down domain
    interactive: true
    dir: environments/{{.ENVIRONMENT}}/{{.MODULE}}
    cmds:
    - "{{.GRUNT}} init -upgrade"
    - "{{.GRUNT}} {{.OP}}"
    vars:
      ENVIRONMENT: prod
      MODULE: dns
      OP: destroy

  #################################
  ### Utilities / Port-Forwards
  #################################
  login:doctl:
    desc: Log into Digital Ocean (get a kubeconfig)
    interactive: true
    cmds:
    - doctl kubernetes cluster kubeconfig save $TF_VAR_cluster_name

  login:argo-workflows:
    desc: Get the Argo Workflows token
    interactive: true
    cmds:
      - |
        printf '{{.GREEN}}' >&2
        echo '=== kube context ========'
        echo '{{.RED}}{{.KUBECTX}}{{.GREEN}}'
        echo '=== Argo Bearer Token ========'
        echo '{{.ARGO_TOKEN}}'
        echo '========================='
      - "{{.KUBECTL}} port-forward -n argo svc/argo-server 2746:2746"
    vars:
      KUBECTX:
        sh: "{{.KUBECTL}} config current-context"
      ARGO_POD:
        sh: |
          {{.KUBECTL}} get pod -n argo | grep argo-server | awk '{print $1}'
      ARGO_TOKEN:
        sh: |
          {{.KUBECTL}} -n argo exec {{.ARGO_POD}} -- argo auth token
  
  login:argo-cd:
    desc: Get the Argo Workflows token
    interactive: true
    silent: true
    cmds:
      - |
        printf '{{.BLUE}}' >&2
        echo '=== kube context ========'
        printf '{{.YELLOW}}' >&2
        echo '{{.KUBECTX}}'
        printf '{{.BLUE}}' >&2
        echo '=== ArgoCD Login ========'
        printf '{{.YELLOW}}' >&2
        echo 'username: admin'
        echo 'password: {{.ARGOCD_PASSWORD}}'
        printf '{{.BLUE}}' >&2
        echo '========================='
        printf '{{.RESET}}' >&2
      - "{{.KUBECTL}} port-forward -n argocd svc/argocd-server 8000:80"
    vars:
      KUBECTX:
        sh: "{{.KUBECTL}} config current-context"
      ARGOCD_PASSWORD:
        sh: |
          {{.KUBECTL}} get secret argocd-initial-admin-secret \
            -n argocd \
            -o jsonpath="{.data.password}" | base64 -d

  buildrun:rebuild:
    desc: rebuild the demo-app images
    cmds:
    - task: buildrun:prune
    - cmd: echo "wait for deletion"
    - task: buildrun:wait
    - task: imago

  buildrun:prune:
    desc: remove old buildruns
    cmds:
      - |
          kubectl delete buildruns.shipwright.io \
            -n shipwright-build --all

  buildrun:wait:
    desc: wait for rebuilds to finish
    cmds:
    - |
        set -o pipefail;
        while {{.KUBECTL}} get buildruns.shipwright.io \
          -n shipwright-build -o json \
          | jq -e '.items | length == 0' > /dev/null; do
          echo "Waiting for buildruns to spawn...";
          sleep 10;
        done
    - |
        set -o pipefail;
        while {{.KUBECTL}} get buildruns.shipwright.io \
           -n shipwright-build -o json \
           | jq -e '.items | any(.status.output == null)' > /dev/null; do
           {{.KUBECTL}} get buildruns.shipwright.io -n shipwright-build;
           echo "Some buildruns have not finished. Waiting...";
           sleep 5;
        done

  imago:
    desc: refresh images from new sha
    deps: [buildrun:wait]
    interactive: true
    silent: false
    cmds:
      - |
          kubectl delete jobs -n web-system \
            --field-selector status.successful=1
      - |
          kubectl create job -n web-system \
            --from=cronjob/imago imago-{{.TIMESTAMP}}
    vars:
      TIMESTAMP:
        sh: "date +'%s'"
